qq_plot <- ggplot(data = as.data.frame(residuals_arima), aes(sample = .resid)) +
stat_qq() +
stat_qq_line() +
labs(title = "Q-Q Plot of ARIMA(0,1,1)(0,1,1)[12] Residuals", x = "Theoretical Quantiles", y = "Sample Quantiles")
residual_plot|acf_plot |qq_plot
# Ljung Box Test on residuals
resid.ts<-model.bic %>%
augment() %>%
select(.resid) %>%
as.ts()
# Box.test(resid.ts, lag = 24, type = "Ljung-Box")
# Generate forecasts from model.bic
forecast_arima <- model.bic %>%
forecast(h = "25 years")  # Forecast horizon up to 2022
# Plot the forecasts along with the observed data
autoplot(co2_tsib, value) +  # Plot original data
autolayer(forecast_arima, color = "cornflowerblue") +  # Add forecast
labs(title = "CO2 Levels: Observed and Forecasted (up to 2022)",
x = "Year", y = "CO2 concentrations (ppmv)") +
scale_x_yearmonth(date_breaks = "5 years", date_labels = "%Y") +
guides(colour = guide_legend(title = "Series"))
# Generate forecasts for a long horizon (up to 2100)
long_term_forecast <- model.bic %>%
forecast(h = "103 years")  # Forecast horizon (assuming we want predictions up to 2100)
# Convert the forecast to a data frame for easier inspection
forecast_df <- as.data.frame(long_term_forecast)
# Look at when CO2 levels are predicted to reach 420 ppm
threshold_420 <- forecast_df %>%
filter(.mean >= 420 & .mean < 421)
# Extract the mean and variance from threshold_420
mean_420 <- threshold_420$.mean  # Mean value
variance_420 <- variance(threshold_420$value)  # Extract variance from the distribution
# Calculate standard deviation
sd_420 <- sqrt(variance_420)
# Calculate the 80% confidence interval
ci_lower_420 <- mean_420 - 1.28 * sd_420
ci_upper_420 <- mean_420 + 1.28 * sd_420
# Look at when CO2 levels are predicted to reach 500 ppm
threshold_500 <- forecast_df %>%
filter(.mean >= 500 & .mean < 501)
# Extract the mean and variance from threshold_420
mean_500 <- threshold_500$.mean  # Mean value
variance_500 <- variance(threshold_500$value)  # Extract variance from the distribution
# Calculate standard deviation
sd_500 <- sqrt(variance_500)
# Calculate the 80% confidence interval
ci_lower_500 <- mean_500 - 1.28 * sd_500
ci_upper_500 <- mean_500 + 1.28 * sd_500
# Looking at confidence intervals for first and last time 420 level is reached
# c(ci_lower_420[1],  ci_upper_420[1])
# c(ci_lower_420[length(ci_lower_420)], ci_upper_420[length(ci_upper_420)])
# Looking at confidence intervals for first and last time 500 level is reached
# c(ci_lower_500[1],  ci_upper_500[1])
# c(ci_lower_500[length(ci_lower_500)], ci_upper_500[length(ci_upper_500)])
# Create a data frame with blanks
co2_table <- data.frame(
`CO2 Level` = c("420 ppm", "500 ppm"),  # CO2 levels to track
`First Month` = c("2031 May", "2083 Apr"),
`First Value` = c("420.1 (402.3, 438.0)", "500.4 (437.9,562.9)"),
`Last Month` = c("2035 Oct", "2085 Dec"),
`Last Value` = c("420.4 (399.5, 441.3)", "500.9 (435.7,566.2)")
)
# Print the table using kable
kable(co2_table, caption = "CO2 Levels and Forecasted Times with 80\\% Confidence Intervals")%>%
kable_styling(font_size =9,latex_options = "HOLD_position")  # Adjust the font size here (change to any desired value)
# Extract the forecast for the year 2100
forecast_2100 <- forecast_df %>%
filter(year(index) == 2100)
# Create variance column
forecast_2100$std <- sqrt(variance(forecast_2100$value))
forecast_2100_table<-forecast_2100 %>%select("index",".mean","std") %>%
mutate(.mean = round(.mean,1), std = round(std,1)) %>%
rename(
Date =index,
Value = .mean,
SD = std
)
# Print forecast for 2100
kable(forecast_2100_table, caption = "CO2 Forecasts in 2100")%>%
kable_styling(font_size = 9,latex_options = "HOLD_position")  # Adjust the font size here (change to any desired value)
# get co2 data from Mauna Loa weekly CO2 records url
url <- "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.txt"
# convert txt file to readable data
data_raw <- read.delim(url, skip = 37, header = FALSE, sep = "",
stringsAsFactors = FALSE)
# Adjust these column names to match the file's structure exactly
colnames(data_raw) <- c("year", "month", "day", "date_decimal", "value", "ndays",
"1_year_ago", "10_years_ago", "increase_since_1800")
# Add week numbering index
data_raw <- data_raw %>%
mutate(index = row_number())
#  Clean 1_year_ago and 10_years_ago columns
data_processed <- data_raw %>%
mutate(
`value` = ifelse(`value` <= -999.99, NA, `value`),
`1_year_ago` = ifelse(`1_year_ago` <= -999.99, NA, `1_year_ago`),
`10_years_ago` = ifelse(`10_years_ago` <= -999.99, NA, `10_years_ago`)
) %>%
mutate(datetime = make_datetime(year, month, day), # Convert the timestamp columns (year, month, day, hour) to a datetime object
datetime = as.Date(datetime)) %>%
filter(!is.na(value))  # Remove any NA values in CO2 concentration
# Ensure unique, ordered datetime values
data_clean <- data_processed %>%
arrange(datetime) %>%
distinct(datetime, .keep_all = TRUE) %>%  # Remove duplicates, if any
select(datetime, value)
# create time series object
co2_present <- ts(data_clean$value, frequency = 52, start = c(year(min(data_processed$datetime)), 1))
# import data
new_co2_tsib <- as_tsibble(data_processed, index = datetime)
# new_co2_tsib <- new_co2_tsib %>% mutate(datetime = yearweek(datetime))
# monthly time series with the line of best fit
new_co2_trend_plot <- new_co2_tsib %>%
ggplot(aes(x = datetime, y = value)) +
geom_line(color = 'black', size = .5) +
labs(title = 'Increasing CO2 concentration from 1997 to Present',x = 'Year', y = 'CO2 concentrations (ppmv)') +
scale_x_yearmonth(date_breaks = "5 years")
# average_yearly_increase
new_co2_tsib_yearly_change <- new_co2_tsib %>% as_tibble() %>%
group_by(year) %>%
summarise(`yearly_co2` = mean(value)) %>%
ungroup() %>%
mutate(lag_co2 = lag(yearly_co2),
change = yearly_co2 - lag_co2,
percent_change = ((yearly_co2 - lag_co2)/lag_co2)*100)
# getting average increase (i.e. size of the trend)
new_yearly_mean <- mean(new_co2_tsib_yearly_change$change, na.rm = T) # average 1.90 units of co2 change each year
new_yearly_sd <- sd(new_co2_tsib_yearly_change$change, na.rm = T) # with a sd of .61 units of co2
new_change_hist <- ggplot(new_co2_tsib_yearly_change, aes(x = change)) +
geom_histogram(color = 'gray20', fill = 'gray', binwidth = .25) +
scale_x_continuous(breaks = seq(floor(min(new_co2_tsib_yearly_change$change, na.rm =T)),
ceiling(max(new_co2_tsib_yearly_change$change, na.rm =T)), by = 0.25)) +
labs(
title = "Histogram of Yearly Changes in CO2 ppmv",
x = "Change",
y = "Frequency"
)
new_co2_trend_plot / new_change_hist
# inspecting acf and graph of co2 concentrations over time
new_co2_acf <- acf(new_co2_tsib$value, plot = F)
new_co2_acf_plot <-  autoplot(new_co2_acf) +
labs(title = "ACF plot of monthly CO2 Concentrations", x = 'Lag', y = 'Autocorrelation',subtitle="1997-Sep 2024")
# Monthly aggregated dataset
new_co2_monthly_averages <- data_clean %>%
mutate(month = month(datetime)) %>%  # Convert datetime to month format
group_by(month) %>%  # Group by month to aggregate monthly averages
summarise(co2_monthly_ave = mean(value, na.rm = TRUE)) %>%  # Calculate monthly average
ungroup() %>%
as_tsibble(index = month)  # Convert to tsibble
# # make a monthly average co2 plot
# new_monthly_co2_ave_plot <- new_co2_monthly_averages %>%
#   mutate(month_str = factor(month.abb[month], levels = month.abb)) %>%
#   ungroup() %>%
#   ggplot(aes(x = month_str, y = co2_monthly_ave, group = 1)) +
#   geom_line(size = .8, color = 'purple4') +
#   geom_point(size = 1.5) +
#   ggtitle("Average CO2 Concentrations Across\nEach Month") +
#   xlab('Month') +
#   ylab('Co2 Concentrations (ppmv)') +
#   theme(axis.text.x = element_text(angle = 45))
# Convert your data to a tsibble (if not already in tsibble format)
data_tsibble <- as_tsibble(data_clean, index = datetime)
data_tsibble <- data_tsibble %>%
fill_gaps()
# Use gg_season to plot seasonality
gg_season_plot <- gg_season(data_tsibble, value) +
labs(
title = "Seasonal Plot of Weekly CO2 Concentrations",
x = "Week of the Year",
y = "CO2 Concentrations (ppmv)"
)
new_co2_acf_plot | gg_season_plot
# checking for stationarity
#adf.test(co2_present)
# making a plot to show how the relationship looks like with yearly averages over the seasons
new_yearly_ave_w_residuals <- new_co2_tsib %>% as_tibble() %>%
mutate(year = year(datetime)) %>%
group_by(year) %>%
mutate(`Yearly_Co2` = mean(value)) %>%
mutate(residual = value - `Yearly_Co2`) %>%
pivot_longer(cols = c(value, `Yearly_Co2`, residual), names_to = "type", values_to = "Yearly Co2") %>%
mutate(residual_bool = if_else(type == "residual", "Residuals", "Monthly Time Series Plotted on Yearly Average Co2"))
new_yearly_ave_w_residuals_plot <- new_yearly_ave_w_residuals %>%
ggplot(aes(x = datetime, y = `Yearly Co2`, color = type)) +
geom_line() +
facet_wrap(~residual_bool, scales = "free_y", ncol = 1) +
xlab('Date') +
theme(legend.position = "none")
new_yearly_ave_w_residuals_plot
# Generate future monthly dates starting from January 1998 to September 2024
future_index <- seq(from = as.Date("1998-01-01"),  # Start in January 1998
to = as.Date("2024-09-30"), by = "1 month")  # Generate monthly dates up to Sep 2024
# Convert future_index to yearmonth format
future_index <- yearmonth(future_index)
# Create future data with month and season columns
future_data <- tibble(
index = future_index,  # Future index (dates)
month = factor(month(index)),
year = factor(year(index)))
# Define a function to convert months into seasons
future_data$season <- case_when(
month(future_data$index) %in% c(12, 1, 2) ~ "Winter",
month(future_data$index) %in% c(3, 4, 5) ~ "Spring",
month(future_data$index) %in% c(6, 7, 8) ~ "Summer",
month(future_data$index) %in% c(9, 10, 11) ~ "Autumn"
)
# Convert season into a factor
future_data$season <- factor(future_data$season, levels = c("Winter", "Spring", "Summer", "Autumn"))
future_data<- future_data %>%
as_tsibble(index = index)
forecast_poly_season <- co2_models_x %>%
select(poly_season_model) %>%
forecast(new_data = future_data)  # Use a forecast horizon from the last observed point
autoplot(new_co2_tsib, value) +  # Plot original data  # Plot original data
autolayer(forecast_poly_season, color = "cornflowerblue") +  # Add forecasted values
labs(title = "Forecasted CO2 Concentrations Compared to Observed Values",
x = "Year", y = "CO2 concentrations (ppmv)") +
scale_x_yearmonth(date_breaks = "5 years", date_labels = "%Y") +
guides(colour = guide_legend(title = "Series"))
# Generate forecasts from model.bic
forecast_arima <- model.bic %>%
forecast(new_data = future_data)  # Forecast horizon up to 2024
autoplot(forecast_arima, color = "cornflowerblue") +  # Add forecast first
autolayer(new_co2_tsib, value, color = "black") +  # Plot observed data on top
labs(title = "Forecasted CO2 Concentrations Compared to Observed Values",
x = "Year", y = "CO2 concentrations (ppmv)") +
scale_x_yearmonth(date_breaks = "5 years", date_labels = "%Y") +
guides(colour = guide_legend(title = "Series"))
# getting root mean absolute error and root mean squared errors to compare models
# getting actual values
actual_values <- new_co2_tsib %>%
index_by(month = yearmonth(datetime)) %>%
summarise(value = mean(value, na.rm = T)) %>%
filter(month >= yearmonth('1998 Jan') & month <= yearmonth('2024 Sep')) %>%
pull(value)
# poly forecasted values
poly_forecast_values <- forecast_poly_season %>% pull(.mean)
#arima forecasted values
arima_forecast_values <- forecast_arima %>%
filter(index <= yearmonth('2024 Sep')) %>%
pull(.mean)
# Mean Absolute Error (MAE)
mae_poly <- mean(abs(actual_values - poly_forecast_values)) # ~ 12.3
mae_arima <- mean(abs(actual_values - arima_forecast_values)) # ~ 5.8
# Root Mean Squared Error (RMSE)
rmse_poly <- sqrt(mean((actual_values - poly_forecast_values)^2)) # ~ 15.3
rmse_arima <- sqrt(mean((actual_values - arima_forecast_values)^2)) # ~ 7.1
# Compare all four values
# mae_poly
# mae_arima
# rmse_poly
# rmse_arima
# statistically comparing performance using the Diebold-Mariano test
# Calculate forecast errors
errors_poly <- actual_values - poly_forecast_values
errors_arima <- actual_values - arima_forecast_values
# Perform Diebold-Mariano test
# dm.test(errors_poly, errors_arima, alternative = "two.sided", h = 1, power = 2)
# p-value less than .05, may reject the null hypothesis that the two errors are equal
new_co2_tsib <- new_co2_tsib %>%
fill_gaps()
# Impute using spline interpolation for the 18 missing values
new_co2_tsib_impute <- new_co2_tsib %>%
mutate(value = na_interpolation(value, option = "spline")) %>% # Using spline interpolation
select(datetime, value)
# Use decomposition
stl_model <- new_co2_tsib_impute %>%
model(STL(value ~ season(window = "periodic")))  # STL decomposition with seasonal component
# Extract the components (trend, season, remainder) from the STL model
stl_components <- components(stl_model)
# Plot the components to see how STL decomposed the data
stl_plot <- autoplot(stl_components) +
labs(title = "STL Decomposition of CO2 Data",
y = "CO2 concentrations (ppmv)")
stl_plot
# Convert datetime to yearweek format
stl_components <- stl_components %>%
mutate(datetime = yearweek(datetime))
new_co2_tsib_impute <- new_co2_tsib_impute %>%
mutate(datetime = yearweek(datetime))
# Define training and test date ranges
train_end_date <- yearweek("2022-09-25")  # End of September 2022
test_start_date <- yearweek("2022-10-02")  # Start of October 2022
test_end_date <- yearweek("2024-09-29")    # End of September 2024
# Seasonally Adjusted (SA) training and test sets
# SA Training set
train_SA <- stl_components %>%
select(datetime, trend) %>%
filter(datetime <= train_end_date)
# SA Test set
test_SA <- stl_components %>%
select(datetime, trend) %>%
filter(datetime >= test_start_date & datetime <= test_end_date)
# Non-Seasonally Adjusted (NSA) training and test sets
# NSA Training set
train_NSA <- new_co2_tsib_impute %>%
select(datetime, value) %>%
filter(datetime <= train_end_date)
# NSA Test set
test_NSA <- new_co2_tsib_impute %>%
select(datetime, value) %>%
filter(datetime >= test_start_date & datetime <= test_end_date)
# Compute the ACF plot for NSA data
train_NSA_acf <- ACF(train_NSA, difference(value,lag = 1), lag_max = 104) %>% autoplot()+
labs(title = "ACF plot of NSA Weekly CO2 Concentrations",subtitle = "Training Set, differenced 1st order", x = 'Lag', y = 'Autocorrelation')
# Compute the PACF plot for NSA data
train_NSA_pacf <- PACF(train_NSA, difference(value,lag=1), lag_max = 104) %>% autoplot()+
labs(title = "PACF plot of NSA Weekly CO2 Concentrations",subtitle = "Training Set, differenced 1st order",
x = 'Lag', y = 'Partial Autocorrelation')
# Compute the ACF plot for SA data
train_SA_acf <- ACF(train_SA, difference(trend,lag=1), lag_max = 104) %>%
autoplot() +
labs(title = "ACF plot of SA Weekly CO2 Concentrations", subtitle = "Training Set, differenced 1st order",
x = 'Lag', y = 'Partial Autocorrelation')
# Compute the PACF plot for SA data
train_SA_pacf <- PACF(train_SA, difference(trend,lag=1), lag_max = 104) %>%
autoplot() +
labs(title = "PACF plot of SA Weekly CO2 Concentrations", subtitle = "Training Set, differenced 1st order",
x = 'Lag', y = 'Partial Autocorrelation')
# Display the plots
(train_NSA_acf | train_NSA_pacf) / (train_SA_acf | train_SA_pacf)
# NSA
# Fit ARIMA model by testing different lags using the BIC criterion
model.bic.present.nsa <- train_NSA %>%
model(
arima111011 = ARIMA(value ~ 0 + pdq(1,1,1) + PDQ(0,1,1)),
auto = ARIMA(value, stepwise = FALSE, ic = "bic")
)
# Extract the glances
nsa.arima111011.report <- model.bic.present.nsa %>%
select(arima111011) %>%
glance()
nsa.auto.report <- model.bic.present.nsa %>%
select(auto) %>%
glance()
# Look at report for auto
# model.bic.present.nsa %>%
#   select(auto) %>%
#   report()
#SA
# Fit ARIMA model by testing different lags using the BIC criterion
model.bic.present.sa <- train_SA %>%
model(
arima110000 = ARIMA(trend ~ pdq(1,1,0) + PDQ(0,0,0), ic = "bic"),
arima111000 = ARIMA(trend ~ pdq(1,1,1) + PDQ(0,0,0), ic = "bic"),
arima210000 = ARIMA(trend ~ pdq(2,1,0) + PDQ(0,0,0), ic = "bic")
)
# Extract the report from the best ARIMA model
sa.arima110000.report <- model.bic.present.sa %>%
select(arima110000)%>%
glance()
sa.arima111000.report <- model.bic.present.sa %>%
select(arima111000) %>%
glance()
sa.arima210000.report <- model.bic.present.sa %>%
select(arima210000)%>%
glance()
# NSA: Create a data frame for NSA models
nsa_table <- data.frame(
Model = c("ARIMA(1,1,1)(0,1,1)", "Auto: ARIMA(0,1,3)(2,1,0)"),
AICc = c(nsa.arima111011.report$AICc, nsa.auto.report$AICc),
BIC = c(nsa.arima111011.report$BIC, nsa.auto.report$BIC),
LogLik = c(nsa.arima111011.report$log_lik, nsa.auto.report$log_lik)
)
# SA: Create a data frame for SA models
sa_table <- data.frame(
Model = c("ARIMA(1,1,0)", "ARIMA(1,1,1)", "ARIMA(2,1,0)"),
AICc = c(sa.arima110000.report$AICc, sa.arima111000.report$AICc, sa.arima210000.report$AICc),
BIC = c(sa.arima110000.report$BIC, sa.arima111000.report$BIC, sa.arima210000.report$BIC),
LogLik = c(sa.arima110000.report$log_lik, sa.arima111000.report$log_lik, sa.arima210000.report$log_lik)
)
kable(nsa_table, caption = "NSA ARIMA Model Results")%>%
kable_styling(font_size = 9,latex_options = "HOLD_position")
kable(sa_table, caption = "SA ARIMA Model Results")%>%
kable_styling(font_size = 9,latex_options = "HOLD_position")
# Extract fitted values for the NSA ARIMA model
nsa_fitted <- model.bic.present.nsa %>%
select(arima111011) %>%
fitted()
# Generate forecasts for the NSA ARIMA model
nsa_forecast <- model.bic.present.nsa %>%
select(arima111011) %>%
forecast(new_data = test_NSA)
# Plot the fitted values for training, forecast for test data, and actual data
nsa_forecast_plot<-autoplot(nsa_fitted,.fitted, color = "cornflowerblue") +  # Fitted values for training data
autolayer(train_NSA, value, color = "black") +  # Actual values for training data
autolayer(nsa_forecast, color = "cornflowerblue") +  # Forecast for test data
autolayer(test_NSA, value, color = "black") +  # Actual values for test data
labs(title = "NSA: Assessing ARIMA(1,1,1)(0,1,1)\nForecasted Values On Test Set", x = "Year", y = "CO2 concentrations (ppmv)") +
coord_cartesian(xlim = c(as.Date("2020-01-01"), NA), ylim=c(375,450)) # Limit to data from 2020 onwards
nsa_full_plot<-autoplot(nsa_fitted,.fitted, color = "cornflowerblue") +  # Fitted values for training data
autolayer(train_NSA, value, color = "black",alpha = 0.8) +  # Actual values for training data
autolayer(nsa_forecast, color = "cornflowerblue") +  # Forecast for test data
autolayer(test_NSA, value, color = "black") +  # Actual values for test data
labs(title = "NSA: Comparing ARIMA(1,1,1)(0,1,1)\nFit on Training Data", x = "Year", y = "CO2 concentrations (ppmv)")
# Extract fitted values for the SA ARIMA model
sa_fitted <- model.bic.present.sa %>%
select(arima110000) %>%
fitted()
# Generate forecasts for the SA ARIMA model
sa_forecast <- model.bic.present.sa %>%
select(arima110000) %>%
forecast(new_data = test_SA)
# Plot the fitted values for training, forecast for test data, and actual data
sa_forecast_plot<-autoplot(sa_fitted,.fitted,color = "cornflowerblue") +  # Fitted values for training data
autolayer(train_SA, trend, color = "black") +  # Actual values for training data
autolayer(sa_forecast,color = "cornflowerblue") +  # Forecast for test data
autolayer(test_SA, trend, color = "black") +  # Actual values for test data
labs(title = "SA: Assessing ARIMA(1,1,0)\nForecasted Values On Test Set", x = "Year", y = "CO2 concentrations (ppmv)") +
coord_cartesian(xlim = c(as.Date("2020-01-01"), NA), ylim=c(375,450))  # Limit to data from 2020 onwards
# Plot the fitted values for training, forecast for test data, and actual data
sa_full_plot<-autoplot(sa_fitted,.fitted,color = "cornflowerblue") +  # Fitted values for training data
autolayer(train_SA, trend, color = "black", alpha = 0.8) +  # Actual values for training data
autolayer(sa_forecast,color = "cornflowerblue") +  # Forecast for test data
autolayer(test_SA, trend, color = "black") +  # Actual values for test data
labs(title = "SA: Comparing ARIMA(1,1,0)\nFit on Training Data", x = "Year", y = "CO2 concentrations (ppmv)")
(sa_full_plot | nsa_full_plot)/
( sa_forecast_plot| nsa_forecast_plot)
# NSA: Calculate MSE and MAE for training set (fitted values)
nsa_train_errors <- nsa_fitted %>%
left_join(train_NSA, by = "datetime") %>%
mutate(
se = (value - .fitted)^2,
ae = abs(value - .fitted)
)
nsa_rmse_train <- sqrt(mean(nsa_train_errors$se))
nsa_mae_train <- mean(nsa_train_errors$ae)
# SA: Calculate MSE and MAE for training set (fitted values)
sa_train_errors <- sa_fitted %>%
left_join(train_SA, by = "datetime") %>%
mutate(
se = (trend - .fitted)^2,
ae = abs(trend - .fitted)
)
sa_rmse_train <- sqrt(mean(sa_train_errors$se))
sa_mae_train <- mean(sa_train_errors$ae)
# NSA: Calculate MSE and MAE for test set (forecasted values)
nsa_test_errors <- nsa_forecast %>%
left_join(test_NSA, by = "datetime") %>%
mutate(
se = (value.y - .mean)^2,
ae = abs(value.y - .mean)
)
nsa_rmse_test <- sqrt(mean(nsa_test_errors$se))
nsa_mae_test <- mean(nsa_test_errors$ae)
# SA: Calculate MSE and MAE for test set (forecasted values)
sa_test_errors <- sa_forecast %>%
left_join(test_SA, by = "datetime") %>%
mutate(
se = (trend.y - .mean)^2,
ae = abs(trend.y - .mean)
)
sa_rmse_test <- sqrt(mean(sa_test_errors$se))
sa_mae_test<- mean(sa_test_errors$ae)
# Create a data frame to store the RMSE and MAE results
model_comparison <- data.frame(
Metric = c("RMSE (Training)", "MAE (Training)", "RMSE (Test)", "MAE (Test)"),
`NSA ARIMA Model` = c(nsa_rmse_train, nsa_mae_train, nsa_rmse_test, nsa_mae_test),
`SA ARIMA Model` = c(sa_rmse_train, sa_mae_train, sa_rmse_test, sa_mae_test)
)
# Use kable to display the comparison table
kable(model_comparison, caption = "Comparison of NSA and SA Models on Training and Test Sets")%>%
kable_styling(font_size = 9,latex_options = "HOLD_position")
SA_poly_model <- train_SA %>%
model(
poly_model = TSLM(trend ~ poly(datetime, 3,raw = TRUE))     # Cubic polynomial time trend model
)
fitted_SA_poly<- SA_poly_model %>%
select(poly_model) %>%
fitted()
forecast_SA_poly <- SA_poly_model %>%
select(poly_model) %>%
forecast(new_data = test_SA)  # Use a forecast horizon from the last observed point
SA_poly_full_plot <- autoplot(train_SA, trend) +  # Plot original data  # Plot original data
autolayer(fitted_SA_poly, .fitted, color = "cornflowerblue")+
autolayer(forecast_SA_poly, color = "cornflowerblue") +  # Add forecasted values
autolayer(test_SA, trend)+
labs(title = "Polynomial (3) Model Fit on SA Training Set",
x = "Year", y = "CO2 concentrations (ppmv)") +
scale_x_yearmonth(date_breaks = "5 years", date_labels = "%Y") +
guides(colour = guide_legend(title = "Series"))
SA_poly_forecast_plot <- autoplot(train_SA, trend) +  # Plot original data  # Plot original data
autolayer(fitted_SA_poly, .fitted, color = "cornflowerblue")+
autolayer(forecast_SA_poly, color = "cornflowerblue") +  # Add forecasted values
autolayer(test_SA, trend)+
labs(title = "Assessing Polynomial (3) Model on SA Test Set",
x = "Year", y = "CO2 concentrations (ppmv)") +
scale_x_yearmonth(date_breaks = "5 years", date_labels = "%Y") +
coord_cartesian(xlim = c(as.Date("2020-01-01"), NA), ylim=c(375,450)) # Limit to data from 2020 onwards
SA_poly_full_plot | SA_poly_forecast_plot
# Calculate RMSE and MAE for poly (3) model
sa_poly_train_errors <- train_SA %>%
left_join(fitted_SA_poly, by = "datetime") %>%
mutate(
se = (trend - .fitted)^2,
ae = abs(trend - .fitted)
)
sa_poly_test_errors <- test_SA %>%
left_join(forecast_SA_poly, by = "datetime") %>%
mutate(
se = (trend.x - .mean)^2,
ae = abs(trend.x - .mean)
)
sa_poly_rmse_train <- sqrt(mean(sa_poly_train_errors$se))
sa__poly_mae_train<- mean(sa_poly_train_errors$ae)
sa_poly_rmse_test <- sqrt(mean(sa_poly_test_errors$se))
sa__poly_mae_test<- mean(sa_poly_test_errors$ae)
# Look at the values
# sa_poly_rmse_train
# sa__poly_mae_train
# sa_poly_rmse_test
# sa__poly_mae_test
